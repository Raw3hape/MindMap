//
//  RecordingViewModel.swift
//  MindMap
//
//  Created by Nikita Sergyshkin on 05/08/2025.
//

import Foundation
import Combine
import SwiftUI
import Speech

// MARK: - Recording View Model
@MainActor
class RecordingViewModel: ObservableObject {
    @Published var isRecording = false
    @Published var isProcessing = false
    @Published var recordingDuration: TimeInterval = 0
    @Published var recordingLevel: Float = 0
    @Published var manualText = ""
    @Published var errorMessage: String?
    @Published var showError = false
    @Published var processingMode: ProcessingMode = .speechOnly
    @Published var useOfflineProcessing = true
    @Published var speechRecognitionAvailable = false
    
    private let audioManager = AudioManager.shared
    private let openAIService = OpenAIService.shared
    private let speechService = SpeechRecognitionService.shared
    private let coreDataManager = CoreDataManager.shared
    private var cancellables = Set<AnyCancellable>()
    private var currentRecordingURL: URL?
    
    init() {
        setupBindings()
        checkSpeechAvailability()
    }
    
    private func setupBindings() {
        // –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∑–∞–ø–∏—Å–∏
        audioManager.$recordingState
            .map { state in
                switch state {
                case .recording:
                    return true
                default:
                    return false
                }
            }
            .assign(to: \.isRecording, on: self)
            .store(in: &cancellables)
        
        // –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∑–∞–ø–∏—Å–∏
        audioManager.$recordingDuration
            .assign(to: \.recordingDuration, on: self)
            .store(in: &cancellables)
        
        // –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ–º —É—Ä–æ–≤–µ–Ω—å –∑–≤—É–∫–∞
        audioManager.$recordingLevel
            .assign(to: \.recordingLevel, on: self)
            .store(in: &cancellables)
        
        // –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ–º —Ä–µ–∂–∏–º –æ–±—Ä–∞–±–æ—Ç–∫–∏
        $processingMode
            .sink { [weak self] mode in
                self?.openAIService.setProcessingMode(mode)
            }
            .store(in: &cancellables)
        
        // –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ–º –æ—Ñ–ª–∞–π–Ω —Ä–µ–∂–∏–º
        $useOfflineProcessing
            .sink { [weak self] enabled in
                self?.openAIService.setOfflineFirst(enabled)
            }
            .store(in: &cancellables)
    }
    
    private func checkSpeechAvailability() {
        _Concurrency.Task {
            let hasPermissions = await speechService.requestPermissions()
            await MainActor.run {
                speechRecognitionAvailable = hasPermissions && speechService.isSpeechRecognitionAvailable
                logInfo("üé§ Speech Recognition –¥–æ—Å—Ç—É–ø–µ–Ω: \(speechRecognitionAvailable)", category: .speech)
            }
        }
    }
    
    // MARK: - Recording Actions
    func startRecording() {
        guard audioManager.hasPermission else {
            showErrorMessage("–ù–µ—Ç —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –Ω–∞ –∑–∞–ø–∏—Å—å –∞—É–¥–∏–æ")
            return
        }
        
        currentRecordingURL = audioManager.startRecording()
        if currentRecordingURL == nil {
            showErrorMessage("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å")
        }
    }
    
    func stopRecording() {
        audioManager.stopRecording()
    }
    
    func toggleRecording() {
        if isRecording {
            stopRecording()
        } else {
            startRecording()
        }
    }
    
    // MARK: - Processing
    func processRecording() async {
        await processRecordingWithMode(processingMode)
    }
    
    func processRecordingWithMode(_ mode: ProcessingMode) async {
        guard let audioURL = currentRecordingURL else {
            showErrorMessage("–ù–µ—Ç –∑–∞–ø–∏—Å–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return
        }
        
        isProcessing = true
        
        do {
            let task = try await openAIService.processAudioWithMode(from: audioURL, mode: mode)
            coreDataManager.createTask(task)
            
            // –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
            clearRecording()
            
        } catch {
            showErrorMessage("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø–∏—Å–∏: \(error.localizedDescription)")
        }
        
        isProcessing = false
    }
    
    func processManualText() async {
        guard !manualText.trimmingCharacters(in: .whitespacesAndNewlines).isEmpty else {
            showErrorMessage("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return
        }
        
        isProcessing = true
        
        do {
            let task = try await openAIService.processText(manualText)
            coreDataManager.createTask(task)
            
            // –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
            manualText = ""
            
        } catch {
            showErrorMessage("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞: \(error.localizedDescription)")
        }
        
        isProcessing = false
    }
    
    // MARK: - Utility
    func clearRecording() {
        if let url = currentRecordingURL {
            audioManager.deleteRecording(at: url)
        }
        currentRecordingURL = nil
        recordingDuration = 0
        recordingLevel = 0
    }
    
    func playRecording() {
        guard let url = currentRecordingURL else { return }
        audioManager.playAudio(from: url)
    }
    
    func formatDuration(_ duration: TimeInterval) -> String {
        audioManager.formatDuration(duration)
    }
    
    private func showErrorMessage(_ message: String) {
        errorMessage = message
        showError = true
    }
    
    // MARK: - Validation
    var hasRecording: Bool {
        currentRecordingURL != nil && recordingDuration > 0
    }
    
    var hasManualText: Bool {
        !manualText.trimmingCharacters(in: .whitespacesAndNewlines).isEmpty
    }
    
    var canProcess: Bool {
        !isProcessing && (hasRecording || hasManualText)
    }
    
    // MARK: - Processing Mode Helpers
    func getRecommendedMode() -> ProcessingMode {
        // –í—Å–µ–≥–¥–∞ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º —Ç–æ–ª—å–∫–æ iOS Speech
        return .speechOnly
    }
    
    func switchToRecommendedMode() {
        let recommended = getRecommendedMode()
        if recommended != processingMode {
            processingMode = recommended
        }
    }
    
    var processingModeDescription: String {
        switch processingMode {
        case .speechOnly:
            return "iOS Speech + –ª–æ–∫–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞"
        case .auto:
            return "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä"
        }
    }
}